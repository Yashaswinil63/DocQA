{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.11.1' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Function to get all PDF files in the directory\n",
    "def get_pdf_files(directory):\n",
    "    return [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.pdf')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from each PDF and split it into chunks\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    num_pages = len(reader.pages)\n",
    "    text_chunks = []\n",
    "    for page_num in range(num_pages):\n",
    "        page = reader.pages[page_num]\n",
    "        text = page.extract_text()\n",
    "        # Replace multiple whitespace characters with a single space\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        chunks = split_text_into_chunks(text)\n",
    "        for chunk in chunks:\n",
    "            text_chunks.append((chunk, page_num, pdf_path))\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split text into smaller chunks\n",
    "def split_text_into_chunks(text, chunk_size=1000):\n",
    "    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model for generating embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to generate embeddings for text chunks\n",
    "def generate_embeddings(text_chunks):\n",
    "    texts = [chunk[0] for chunk in text_chunks]\n",
    "    embeddings = model.encode(texts)\n",
    "    return [(embedding, chunk[0], chunk[1], chunk[2]) for embedding, chunk in zip(embeddings, text_chunks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to store embeddings in a FAISS vector database\n",
    "def store_embeddings_in_faiss(embeddings):\n",
    "    dimension = len(embeddings[0][0])\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    vectors = np.array([embedding[0] for embedding in embeddings])\n",
    "    index.add(vectors)\n",
    "    metadata = [(chunk[1], chunk[2], chunk[3]) for chunk in embeddings]\n",
    "    return index, metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the top k similar text chunks based on user query\n",
    "def get_top_k_similar_chunks(query, index, metadata, k=3):\n",
    "    query_embedding = model.encode([query])\n",
    "    distances, indices = index.search(np.array(query_embedding), k)\n",
    "    results = []\n",
    "    for idx in indices[0]:\n",
    "        text, page_num, pdf_path = metadata[idx]\n",
    "        results.append((text, page_num, pdf_path))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  3. Once the Country Code is entered, click the Execute button shown as an icon in the top -left corne r of the screen. 4. The updated Country Code is replicated in the P08 system. \n",
      "Page Number: 34\n",
      "File: C:\\Users\\Yashaswini\\OneDrive\\Desktop\\Capstone\\Genpact_SOP.pdf\n",
      "\n",
      "Text:  4. The updated Country Code is replicated in SAP S/4 HANA (P40) system. The updated Country Code will be available in the system for transaction after the quarterly maintenance Finance week i.e. the 4th Week of every quarter on a Thursday for the quarter months March, June, September and December. \n",
      "Page Number: 32\n",
      "File: C:\\Users\\Yashaswini\\OneDrive\\Desktop\\Capstone\\Genpact_SOP.pdf\n",
      "\n",
      "Text:  2. Executive Summary 2.1 Synopsis The ABC Company has transactions with companies from all over the world. These transactions need to be tracked and the Country Code is a field used to identify transactions of ABC with an associate company from another country. Any request to update a Country Code is rai sed in the Finance Request Form through Fiori. The request is initiated by the Requestor. The key field for the Country Code form is Title, as the Country Code itself cannot be a mandatory field at the Requestor level due to the business requirements. The Requestor uses the search functionality to display all the Country Codes created within the Master Data Governance (MDG) framework to check if the Country Code (for which the request is raised) exists in the system. If the Country Code exists, the requ est to update the Country Code is created. However, if the Country Code does not exist, the Requestor then raises a request to create the Country Code. The ISO Country Code is the key \n",
      "Page Number: 3\n",
      "File: C:\\Users\\Yashaswini\\OneDrive\\Desktop\\Capstone\\Genpact_SOP.pdf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "directory = r'C:\\Users\\Yashaswini\\OneDrive\\Desktop\\Capstone'  # Replace with the path to your PDF directory\n",
    "pdf_files = get_pdf_files(directory)\n",
    "\n",
    "all_text_chunks = []\n",
    "for pdf_file in pdf_files:\n",
    "    text_chunks = extract_text_from_pdf(pdf_file)\n",
    "    all_text_chunks.extend(text_chunks)\n",
    "\n",
    "embeddings = generate_embeddings(all_text_chunks)\n",
    "index, metadata = store_embeddings_in_faiss(embeddings)\n",
    "\n",
    "query = \"What are roles involved in updating a country code are:\"  # Replace with your user query\n",
    "top_chunks = get_top_k_similar_chunks(query, index, metadata)\n",
    "\n",
    "# Print the top chunks with their metadata\n",
    "for text, page_num, pdf_path in top_chunks:\n",
    "    print(f\"Text: {text}\\nPage Number: {page_num}\\nFile: {pdf_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk Count using Tokens and not characters so working  ! he he he :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4f015b96c8420c9dec4195b9632030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yashaswini\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Yashaswini\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3634808a009e4b7e9c57e6c4cc9d1e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b1fc456f4047009a30b4f8aa994cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463e84e1c2194097a276628b7fc66447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3684bafc1041eda22d30c1a8090f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: How to access Hotmail in Outlook? To access your Hotmail account via Outlook, two basic versions are available: the web -based version of Outlook, which can be accessed at outlook.com, and the Outlook application available on your PC. First off, we are going to list out the steps that will help you to use your Windows Live Hotmail account on Outlook.com. 1. Go to Outlook sign -in page, and enter your email address. 2. Click “Next”, and key in your Hotmail password. 3. Click “Connect”. For further details on how to sign in to your Hotmail account, click here to read our article. You may also simply synchronize your emails while using another account on Outlook.com. To do so, do the following. 1. On Outlook.com, click the gear icon to access your settings 2. Select “View all Outlook settings ”. \n",
      "Page Number: 0\n",
      "File: C:\\Users\\Yashaswini\\OneDrive\\Desktop\\Capstone\\test.pdf\n",
      "\n",
      "Text: 3. Go to “Sync email”. 4. Click “Other email accounts” under the “Connected accounts” section. 5. Now, type your name, your Hotmail email address, and your Hotmail password. 6. Click “Ok” to connect your account. In the Outlook application, here are the essential steps to follow. 1. Open the Outlook app. 2. Select “Yes” to set up Outlook to connect to a new email account. 3. Enter your name, Hotmail email address and Hotmail password. 4. Click “Next”. 5. If requested to re -enter your password, please re -enter it, and click “Finish”. If you already have an email account in the app, you would need to simply click “File” in the Outlook app, and then “Add account”. For the next steps, refer to the instructions provided above. \n",
      "Page Number: 1\n",
      "File: C:\\Users\\Yashaswini\\OneDrive\\Desktop\\Capstone\\test.pdf\n",
      "\n",
      "Text:  A sample of the e -mail notification is displayed below: Once the request is sent back to the Requestor, the Requestor will decide whether to resubmit the request or not. \n",
      "Page Number: 20\n",
      "File: C:\\Users\\Yashaswini\\OneDrive\\Desktop\\Capstone\\Genpact_SOP.pdf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from transformers import GPT2Tokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Function to get all PDF files in the directory\n",
    "def get_pdf_files(directory):\n",
    "    return [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.pdf')]\n",
    "\n",
    "# Function to extract text from each PDF and split it into chunks\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    num_pages = len(reader.pages)\n",
    "    text_chunks = []\n",
    "    for page_num in range(num_pages):\n",
    "        page = reader.pages[page_num]\n",
    "        text = page.extract_text()\n",
    "        # Replace multiple whitespace characters with a single space\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        chunks = split_text_into_chunks_by_tokens(text)\n",
    "        for chunk in chunks:\n",
    "            text_chunks.append((chunk, page_num, pdf_path))\n",
    "    return text_chunks\n",
    "\n",
    "# Function to split text into smaller chunks based on tokens\n",
    "def split_text_into_chunks_by_tokens(text, max_tokens=1000):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), max_tokens):\n",
    "        chunk_tokens = tokens[i:i + max_tokens]\n",
    "        chunk_text = tokenizer.decode(chunk_tokens)\n",
    "        chunks.append(chunk_text)\n",
    "    return chunks\n",
    "\n",
    "# Load the pre-trained model for generating embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to generate embeddings for text chunks\n",
    "def generate_embeddings(text_chunks):\n",
    "    texts = [chunk[0] for chunk in text_chunks]\n",
    "    embeddings = model.encode(texts)\n",
    "    return [(embedding, chunk[0], chunk[1], chunk[2]) for embedding, chunk in zip(embeddings, text_chunks)]\n",
    "\n",
    "# Function to store embeddings in a FAISS vector database\n",
    "def store_embeddings_in_faiss(embeddings):\n",
    "    dimension = len(embeddings[0][0])\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    vectors = np.array([embedding[0] for embedding in embeddings])\n",
    "    index.add(vectors)\n",
    "    metadata = [(chunk[1], chunk[2], chunk[3]) for chunk in embeddings]\n",
    "    return index, metadata\n",
    "\n",
    "# Function to get the top k similar text chunks based on user query\n",
    "def get_top_k_similar_chunks(query, index, metadata, k=3):\n",
    "    query_embedding = model.encode([query])\n",
    "    distances, indices = index.search(np.array(query_embedding), k)\n",
    "    results = []\n",
    "    for idx in indices[0]:\n",
    "        text, page_num, pdf_path = metadata[idx]\n",
    "        results.append((text, page_num, pdf_path))\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "directory = r'C:\\Users\\Yashaswini\\OneDrive\\Desktop\\Capstone'  # Replace with the path to your PDF directory\n",
    "pdf_files = get_pdf_files(directory)\n",
    "\n",
    "all_text_chunks = []\n",
    "for pdf_file in pdf_files:\n",
    "    text_chunks = extract_text_from_pdf(pdf_file)\n",
    "    all_text_chunks.extend(text_chunks)\n",
    "\n",
    "embeddings = generate_embeddings(all_text_chunks)\n",
    "index, metadata = store_embeddings_in_faiss(embeddings)\n",
    "\n",
    "query = \"Can I save outlook mail as pdf\"  # Replace with your user query\n",
    "top_chunks = get_top_k_similar_chunks(query, index, metadata)\n",
    "\n",
    "# Print the top chunks with their metadata\n",
    "for text, page_num, pdf_path in top_chunks:\n",
    "    print(f\"Text: {text}\\nPage Number: {page_num}\\nFile: {pdf_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  3. Once the Country Code is entered, click the Execute button shown as an icon in the top -left corne r of the screen. 4. The updated Country Code is replicated in the P08 system. \n",
      "Page Number: 34\n",
      "File: C:\\Users\\Yashaswini\\OneDrive\\Desktop\\Capstone\\Genpact_SOP.pdf\n",
      "\n",
      "Text:  4. The updated Country Code is replicated in SAP S/4 HANA (P40) system. The updated Country Code will be available in the system for transaction after the quarterly maintenance Finance week i.e. the 4th Week of every quarter on a Thursday for the quarter months March, June, September and December. \n",
      "Page Number: 32\n",
      "File: C:\\Users\\Yashaswini\\OneDrive\\Desktop\\Capstone\\Genpact_SOP.pdf\n",
      "\n",
      "Text:  2. Executive Summary 2.1 Synopsis The ABC Company has transactions with companies from all over the world. These transactions need to be tracked and the Country Code is a field used to identify transactions of ABC with an associate company from another country. Any request to update a Country Code is rai sed in the Finance Request Form through Fiori. The request is initiated by the Requestor. The key field for the Country Code form is Title, as the Country Code itself cannot be a mandatory field at the Requestor level due to the business requirements. The Requestor uses the search functionality to display all the Country Codes created within the Master Data Governance (MDG) framework to check if the Country Code (for which the request is raised) exists in the system. If the Country Code exists, the requ est to update the Country Code is created. However, if the Country Code does not exist, the Requestor then raises a request to create the Country Code. The ISO Country Code is the key field to be filled in the FRF as the Country Code itself cannot be a man datory field at the Requestor level due to the business requirements. Once the Requestor enters the title, it cannot be changed. When a Country Code needs to be updated, a request is created by the Requestor through the FRF in Fiori. The Requestor fills th e FRF by answering a series of questions and submits the form to trigger the approval workflow. The roles involved in updating a country code are: • Requestor (Generic) • Business Process Steward • Business Process Leader (BPL) • IT Configuration Team The Busines s Process Steward receives the request through an e -mail notification in his/her inbox along with a hyperlink. He/she reviews the request and searches for the Country Code (for which the update request has been submitted) in Fiori. If the queried Country C ode is not found, the Business Process Steward adds relevant comments in the FRF and terminates the request by rejecting it. An e -mail notification along with a hyperlink is triggered to the Requestor to notify the action taken on the request. However, if the queried Country Code is found, the Business Process Steward enriches the FRF and performs one of the following actions: • Approve : The request is approved and routed to the Business Process Lead. • Reject : The request is rejected and is automatically terminated. The Business Process Steward enters the appropriate comments citing the reason for rejection. • Return : The request is sent back to the Requestor to gather additional information. The Business Process Steward adds his/her comments, seeking additional information that needs to be added to the change request. \n",
      "Page Number: 3\n",
      "File: C:\\Users\\Yashaswini\\OneDrive\\Desktop\\Capstone\\Genpact_SOP.pdf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directory = r'C:\\Users\\Yashaswini\\OneDrive\\Desktop\\Capstone'  # Replace with the path to your PDF directory\n",
    "pdf_files = get_pdf_files(directory)\n",
    "\n",
    "all_text_chunks = []\n",
    "for pdf_file in pdf_files:\n",
    "    text_chunks = extract_text_from_pdf(pdf_file)\n",
    "    all_text_chunks.extend(text_chunks)\n",
    "\n",
    "embeddings = generate_embeddings(all_text_chunks)\n",
    "index, metadata = store_embeddings_in_faiss(embeddings)\n",
    "\n",
    "query = \"What are the roles involved in updating the country code\"  # Replace with your user query\n",
    "top_chunks = get_top_k_similar_chunks(query, index, metadata)\n",
    "\n",
    "# Print the top chunks with their metadata\n",
    "for text, page_num, pdf_path in top_chunks:\n",
    "    print(f\"Text: {text}\\nPage Number: {page_num}\\nFile: {pdf_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
